{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322072e3-6e26-410c-adfc-bca09189e6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f678f266-2ddd-48a4-9a1a-4b044eba2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "    # pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, StepLR\n",
    "torch.set_num_threads(4) # Processor Setting\n",
    "    # VAR\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "    # ESN\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7892ebe-ef6f-4cc0-b752-07c9d27e87f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cae166a-9711-4fe1-9c81-506a49e3290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config path\n",
    "root = '/Volumes/Expansion/User_Backup/b08209033/111-2_IVT_analysis/'\n",
    "file = 'config.json'\n",
    "config_path = os.path.join(root, file)\n",
    "\n",
    "# Import config\n",
    "with open(config_path) as infile:\n",
    "    config = json.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "# Update config\n",
    "    # ML Parameters\n",
    "        # DataLoader\n",
    "config.update({\"ML_hyperparam_lookback\": 7})\n",
    "config.update({\"ML_hyperparam_batch_size\": 32})\n",
    "        # Epoch\n",
    "config.update({\"ML_hyperparam_nepochs\": 1000})\n",
    "config.update({\"ML_hyperparam_early_stop\": 20})\n",
    "        # optim\n",
    "config.update({\"ML_hyperparam_learning_rate\": 3e-4})\n",
    "config.update({\"ML_hyperparam_weight_decay\": 1e-6})\n",
    "    # ML Fpath\n",
    "config.update({\"ML_path_model\": os.path.join(config[\"Path_root\"], \"models\")})\n",
    "config.update({\"ML_fname_model\": \"model.pt\"})\n",
    "\n",
    "# Export config\n",
    "with open(config_path, 'w') as outfile:\n",
    "    json.dump(config, outfile, sort_keys=True)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882dc8a-30d6-4c4f-94cc-d169870275a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pytorch parallel computing (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1521ed-e66a-4fe6-b959-6ccca5e06982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79d625-d9f2-47d1-81ce-28f3e1987dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467e2c2-80ea-4c67-a142-a8db07d607d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split observation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b50818-2931-4170-8c4a-8e48c07d2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config[\"Path_IVT_calculation\"])\n",
    "with np.load(config[\"ML_fname_dataset\"]) as dataset:\n",
    "    train_set = dataset[\"train\"]\n",
    "    valid_set = dataset[\"valid\"]\n",
    "    test_set  = dataset[\"test\"]\n",
    "\n",
    "feature_num = config[\"Var_Feature_num_SVD\"] + config[\"Flag_timeline_feature\"] # optional feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c57994-f4c9-4b67-8cf3-bff65d37a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "train_len = config[\"ML_split_size\"][0] - config[\"ML_hyperparam_lookback\"]\n",
    "X_train = np.zeros((train_len, \n",
    "                    config[\"ML_hyperparam_lookback\"], \n",
    "                    feature_num))\n",
    "Y_train = np.zeros((train_len, \n",
    "                    1, \n",
    "                    feature_num))\n",
    "for i in range(train_len):\n",
    "    X_train[i,:,:] = train_set[i:i+config[\"ML_hyperparam_lookback\"],:]\n",
    "    Y_train[i,:,:] = train_set[i+config[\"ML_hyperparam_lookback\"],:].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df339fc4-1f2f-4d3b-aeb7-f2a51f74418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid set\n",
    "valid_len = config[\"ML_split_size\"][1] - config[\"ML_hyperparam_lookback\"]\n",
    "X_valid = np.zeros((valid_len, \n",
    "                    config[\"ML_hyperparam_lookback\"], \n",
    "                    feature_num))\n",
    "Y_valid = np.zeros((valid_len, \n",
    "                    1, \n",
    "                    feature_num))\n",
    "for i in range(valid_len):\n",
    "    X_valid[i,:,:] = valid_set[i:i+config[\"ML_hyperparam_lookback\"],:]\n",
    "    Y_valid[i,:,:] = valid_set[i+config[\"ML_hyperparam_lookback\"],:].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb80cff4-ee1d-4a43-b3a5-91436c536c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "test_len = config[\"ML_split_size\"][2] - config[\"ML_hyperparam_lookback\"]\n",
    "X_test = np.zeros((test_len, \n",
    "                   config[\"ML_hyperparam_lookback\"], \n",
    "                   feature_num))\n",
    "Y_test = np.zeros((test_len, \n",
    "                   1, \n",
    "                   feature_num))\n",
    "for i in range(test_len):\n",
    "    X_test[i,:,:] = test_set[i:i+config[\"ML_hyperparam_lookback\"],:]\n",
    "    Y_test[i,:,:] = test_set[i+config[\"ML_hyperparam_lookback\"],:].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7fb076-d4f4-4a3e-931c-fd1357164bc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Encapsulate to Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0e872d-736f-49e3-8f63-6b53a0a5eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Tensor\n",
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "Y_train = torch.from_numpy(Y_train).type(torch.FloatTensor)\n",
    "X_valid = torch.from_numpy(X_valid).type(torch.FloatTensor)\n",
    "Y_valid = torch.from_numpy(Y_valid).type(torch.FloatTensor)\n",
    "X_test  = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "Y_test  = torch.from_numpy(Y_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f892226-2c27-41d9-9f38-952e0963dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Dataset\n",
    "train_data = TensorDataset(X_train, Y_train)\n",
    "valid_data = TensorDataset(X_valid, Y_valid)\n",
    "test_data  = TensorDataset(X_test,  Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525a50c7-fca6-471e-9908-fcfcfd28fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To DataLoader\n",
    "train_loader = DataLoader(train_data, \n",
    "                          batch_size = config[\"ML_hyperparam_batch_size\"],\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "valid_loader = DataLoader(valid_data, \n",
    "                          batch_size = config[\"ML_hyperparam_batch_size\"],\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "test_loader  = DataLoader(test_data, \n",
    "                          batch_size = config[\"ML_hyperparam_batch_size\"],\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a70500a-08f0-4fa6-b9ec-59f8499e7ea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3e13d-4595-473c-9adb-8acfdcb3add7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc212b2-09b8-40e8-91de-c68e06bec668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_FC(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GRU_FC, self).__init__()\n",
    "        # Parameter\n",
    "        self.input_length = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_size\n",
    "        # Structure\n",
    "        self.GRU = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.FC = nn.Linear(hidden_size, output_size)\n",
    "        # Weight init\n",
    "        self.GRU.weight_ih_l0.data.fill_(0)\n",
    "        self.GRU.weight_hh_l0.data.fill_(0)\n",
    "        self.FC.weight.data.fill_(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Hidden init\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        # GRU pass\n",
    "        out, (hn) = self.GRU(x, (h0.detach()))\n",
    "        # FC pass\n",
    "        out = self.FC(out[:, -1, :])\n",
    "        # Output\n",
    "        out = torch.reshape(out, (out.size()[0], 1, out.size()[-1]))\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = torch.ones(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9221e22-74b2-4224-b461-1b2298920478",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Execute setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5facef-56f3-40c2-b872-0c81bc617dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    # Pre train stage\n",
    "        # model_dict\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') \n",
    "        # Epoch\n",
    "    n_epochs, step, early_stop_count = config['ML_hyperparam_nepochs'], 0, 0\n",
    "        # Loss function\n",
    "    best_loss = math.inf\n",
    "    criterion = nn.MSELoss(reduction='mean').to(device)\n",
    "    mean_train_loss_record = []\n",
    "    mean_valid_loss_record = []\n",
    "        # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr = config['ML_hyperparam_learning_rate'], \n",
    "                                 weight_decay = config['ML_hyperparam_weight_decay'])\n",
    "        # Scheduler\n",
    "    scheduler_CAWR = CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                 T_0     = 50, \n",
    "                                                 T_mult  = 5, \n",
    "                                                 eta_min = config['ML_hyperparam_weight_decay']/1e4)\n",
    "    scheduler_SLR = StepLR(optimizer, \n",
    "                           step_size = 50, \n",
    "                           gamma     = 0.3)\n",
    "\n",
    "    # Training & Validating stage\n",
    "    # In each epoch\n",
    "        # Learn all train data one time\n",
    "        # Learn all valid data one time\n",
    "        # Evaluate learning progress\n",
    "    for epoch in range(n_epochs):\n",
    "        # Init\n",
    "        model.train() # TRAIN\n",
    "        loss_record = []\n",
    "        for batch, (x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad() # Reset gradient\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred[:,-1,:], y[:,-1,:]) # Calculate loss\n",
    "            loss.backward() # Backward propagation\n",
    "            optimizer.step() # Update model parameter\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "            \n",
    "        scheduler_CAWR.step() # Update learning rate\n",
    "        #scheduler_SLR.step()\n",
    "        \n",
    "        mean_train_loss_record.append(sum(loss_record)/len(loss_record))\n",
    "        \n",
    "        # Init\n",
    "        model.eval() # VALIDATE\n",
    "        loss_record = []\n",
    "        for (x, y) in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred[:,-1,:], y[:,-1,:]) # Calculate loss\n",
    "            # Detach loss\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        # Valid loss\n",
    "        mean_valid_loss_record.append(sum(loss_record)/len(loss_record))\n",
    "        \n",
    "        # Show progress\n",
    "        if (epoch%10==0):\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss_record[-1]:.7f}, Valid loss: {mean_valid_loss_record[-1]:.7f}')\n",
    "        \n",
    "        # Save model parameter if better\n",
    "        if mean_valid_loss_record[-1] < best_loss:\n",
    "            best_loss = mean_valid_loss_record[-1]\n",
    "            os.chdir(config[\"ML_path_model\"])\n",
    "            torch.save(model, config[\"ML_fname_model\"])\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "            \n",
    "        # Early stop\n",
    "        if early_stop_count >= config['ML_hyperparam_early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return mean_train_loss_record, mean_valid_loss_record\n",
    "    \n",
    "    return mean_train_loss_record, mean_valid_loss_record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba8eaa9-5339-41e2-95dd-36d6592b7363",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2abbe4c1-9568-4308-9884-f3702d113a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]: Train loss: 0.0505804, Valid loss: 0.0875815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath_root\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GRU_FC(input_size  \u001b[38;5;241m=\u001b[39m feature_num,\n\u001b[1;32m      3\u001b[0m                hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m160\u001b[39m,\n\u001b[1;32m      4\u001b[0m                output_size \u001b[38;5;241m=\u001b[39m feature_num,\n\u001b[1;32m      5\u001b[0m                num_layers  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# put your model and data on the same computation device.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_loss, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 38\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Reset gradient\u001b[39;00m\n\u001b[1;32m     37\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 38\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:], y[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]) \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     40\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Backward propagation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Pcore_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mGRU_FC.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# GRU pass\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m out, (hn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# FC pass\u001b[39;00m\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFC(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[0;32m~/miniconda3/envs/Pcore_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/Pcore_env/lib/python3.10/site-packages/torch/nn/modules/rnn.py:950\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 950\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    954\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(config[\"Path_root\"])\n",
    "model = GRU_FC(input_size  = feature_num,\n",
    "               hidden_size = 160,\n",
    "               output_size = feature_num,\n",
    "               num_layers  = 1).to(device) # put your model and data on the same computation device.\n",
    "train_loss, valid_loss = trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aeabee-4252-4388-9d6e-6ab0d0195e73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2597a324-56c5-4545-bf6c-659948b2cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2935, 39)\n",
      "(2935, 39)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "GRU_predict = [] # Predict\n",
    "GRU_truth = [] # Ground_truth\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        GRU_predict.append(pred.detach().cpu()[:,-1,:])\n",
    "        GRU_truth.append(y.detach().cpu()[:,-1,:])\n",
    "GRU_predict = torch.cat(GRU_predict, dim=0).numpy()\n",
    "GRU_truth = torch.cat(GRU_truth, dim=0).numpy()\n",
    "print(GRU_predict.shape)\n",
    "print(GRU_truth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b689ed2-eabd-4a90-a407-476c4705da7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf42f2c-d3e8-49b0-bb10-ffe3e013c4b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0922ce-7e69-4415-a1bb-1802b1fb95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_p = config[\"ML_hyperparam_lookback\"]\n",
    "results = VAR(train_set[:,:]).fit(maxlags = AR_p, trend = \"ctt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22aef9c-2a1b-458d-966b-0500eb4c39cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9e1a30f-8207-4cda-a7aa-46960526ceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2935, 39)\n",
      "(2935, 39)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "VAR_predict = [] # Predict\n",
    "VAR_truth = [] # Ground_truth\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    xn = x.detach().cpu().numpy()\n",
    "    yn = y.detach().cpu().numpy()\n",
    "    for j in range(len(xn)):\n",
    "        temp = results.forecast(xn[j], 1)\n",
    "        VAR_predict.append(temp[-1,:])\n",
    "        VAR_truth.append(yn[j,-1,:])\n",
    "VAR_predict = np.array(VAR_predict)\n",
    "VAR_truth = np.array(VAR_truth)\n",
    "print(VAR_predict.shape)\n",
    "print(VAR_truth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ab915b-03e1-4ad2-b7c5-5232ab4dcdc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ESN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adacf80-18fa-485f-a622-8883df2671cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85d902ac-2e13-47b8-9f81-ec8a3a4b66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate((train_set, valid_set, test_set), axis = 0)\n",
    "trainLen = config[\"ML_split_size\"][0] + config[\"ML_split_size\"][1]\n",
    "testLen = len(dataset) - trainLen\n",
    "initLen = int(trainLen/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e30b40-52da-4540-9abe-e753ff560abb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b5acf7-33e2-48a6-b690-ad18a4e914e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reservoir size (Node number)\n",
    "resSize = 500\n",
    "# Reservoir memory (Leaky rate)\n",
    "a = 0.5\n",
    "# Reservoir connectivity (Spectral radius)\n",
    "rho = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdf2db-f1c9-4ef3-a129-2b8f7c95cae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e56adaa-df0d-47e7-a871-f7b74d0c5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature\n",
    "inSize = outSize = config[\"Var_Feature_num_SVD\"] + config[\"Flag_timeline_feature\"] # optional feature\n",
    "\n",
    "# Input weight\n",
    "Win = np.random.rand(resSize, 1+inSize)-0.5\n",
    "\n",
    "# Initial hidden weight\n",
    "W_0 = np.random.rand(resSize, resSize)-0.5\n",
    "\n",
    "# Initial spectral radius (W)\n",
    "rhoW = np.max(np.abs(np.linalg.eig(W_0)[0]))\n",
    "\n",
    "# Hidden weight\n",
    "    # Normalized(scaled) by spectral radius\n",
    "W = W_0 * rho / rhoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832df3a-5d06-469b-b888-ef4d7d294654",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64254214-3439-4cf0-b615-ec2badc7bc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1e-08)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1e-08)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1e-08)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pred = [] # ALL state\n",
    "state_vect = np.zeros([resSize, 1]) # Current state\n",
    "\n",
    "# Evolve current state\n",
    "for t in range(trainLen):\n",
    "    # Observation / innovation / infomation\n",
    "    obs = dataset[t,:]\n",
    "    obs = np.reshape(obs, [inSize,1])\n",
    "    # Update state\n",
    "    state_vect = (1-a)*state_vect + a*np.tanh( np.dot(Win, np.vstack((1, obs))) + np.dot(W, state_vect) )\n",
    "    state_pred.append(np.vstack([1, obs, state_vect]))\n",
    "# Discard spin-up\n",
    "state_pred = state_pred[initLen:]\n",
    "state_pred = np.array(state_pred).reshape(-1, 1+inSize+resSize)\n",
    "\n",
    "# Ground true state\n",
    "state_truth = dataset[initLen+1:trainLen+1,:]\n",
    "\n",
    "# Least Square Error (similar to loss function)\n",
    "ridge = Ridge(alpha = 1e-8)\n",
    "ridge.fit(state_pred, state_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82dd32-3706-457b-ae76-0fa92e6f19a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2bab6e1-251b-495a-81d3-fe85e9058eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2935, 39)\n",
      "(2935, 39)\n"
     ]
    }
   ],
   "source": [
    "ESN_predict = []\n",
    "obs = dataset[trainLen,:]\n",
    "obs = np.reshape(obs, [inSize,1])\n",
    "unit = np.ones((1,1))\n",
    "\n",
    "is_iterative = True\n",
    "\n",
    "step = 0\n",
    "for t in range(testLen-1):\n",
    "    state_vect = (1 - a)*state_vect + a*np.tanh(np.dot(Win, np.vstack((unit, obs))) + np.dot(W, state_vect))\n",
    "    y = ridge.predict(np.vstack((1, obs, state_vect)).T)\n",
    "    ESN_predict.append(y)\n",
    "    step += 1\n",
    "    if ((t <= config[\"ML_hyperparam_lookback\"]-1) or (is_iterative)):\n",
    "        # Iterative step\n",
    "        obs = dataset[trainLen+t+1]\n",
    "        obs = np.reshape(obs, [inSize,1])\n",
    "    else:\n",
    "        obs = y\n",
    "        obs = np.reshape(obs,[inSize,1])\n",
    "    if (np.max(np.abs(obs)) > 1e3):\n",
    "        print(\"!!!\")\n",
    "        break\n",
    "    \n",
    "ESN_predict = np.array(ESN_predict).reshape(-1, outSize)[config[\"ML_hyperparam_lookback\"]-1:]\n",
    "ESN_truth = dataset[trainLen+1:trainLen+step+1,:][config[\"ML_hyperparam_lookback\"]-1:]\n",
    "print(ESN_predict.shape)\n",
    "print(ESN_truth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac926c0-d723-47cf-8ccb-a8884275e2b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2adc6a7-71cd-42fe-94e9-4aa6930e779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2942\n",
      "0.033872075\n",
      "0.01525752794981433\n",
      "0.020817742146679138\n"
     ]
    }
   ],
   "source": [
    "MAE_GRU = np.mean(np.square(GRU_predict - GRU_truth))\n",
    "MAE_VAR = np.mean(np.square(VAR_predict - VAR_truth))\n",
    "MAE_ESN = np.mean(np.square(ESN_predict - ESN_truth))\n",
    "print(config[\"ML_split_size\"][2])\n",
    "print(MAE_GRU)\n",
    "print(MAE_VAR)\n",
    "print(MAE_ESN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b0620-7006-4ce1-ac0a-adc50348b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "time_window = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998c1ca-52c4-4503-84b0-5748fd07f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(GRU_predict[:time_window,mode])\n",
    "plt.plot(GRU_truth[:time_window,mode])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b73c-8a62-42be-a542-08dab80778e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(VAR_predict[:time_window, mode])\n",
    "plt.plot(VAR_truth[:time_window, mode])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d87b8c-f625-402c-900f-c9059107032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ESN_predict[:time_window, mode])\n",
    "plt.plot(ESN_truth[:time_window, mode])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fdd01-3f0e-41d5-9d31-b71a3ed4f008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unused blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd16eb-6011-41cc-9d0a-7e9d9ea1720d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pcore_env",
   "language": "python",
   "name": "pcore_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
