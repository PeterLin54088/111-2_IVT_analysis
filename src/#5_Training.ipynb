{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322072e3-6e26-410c-adfc-bca09189e6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678f266-2ddd-48a4-9a1a-4b044eba2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7892ebe-ef6f-4cc0-b752-07c9d27e87f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae166a-9711-4fe1-9c81-506a49e3290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config path\n",
    "root = '/Volumes/Expansion/User_Backup/b08209033/111-2_IVT_analysis/'\n",
    "file = 'config.json'\n",
    "config_path = os.path.join(root, file)\n",
    "\n",
    "# Import config\n",
    "with open(config_path) as infile:\n",
    "    config = json.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "# Update config\n",
    "# Parameters\n",
    "    # DataLoader\n",
    "config.update({\"ML_hyperparam_lookback\": 7})\n",
    "config.update({\"ML_hyperparam_batch_size\": 32})\n",
    "    # Epoch\n",
    "config.update({\"ML_hyperparam_nepochs\": 1000})\n",
    "config.update({\"ML_hyperparam_early_stop\": 100})\n",
    "    # optim\n",
    "config.update({\"ML_hyperparam_learning_rate\": 1e-4})\n",
    "config.update({\"ML_hyperparam_weight_decay\": 0})\n",
    "# Fpath\n",
    "config.update({\"ML_path_model\": os.path.join(config[\"Path_root\"], \"models\")})\n",
    "config.update({\"ML_fname_model\": \"model.pt\"})\n",
    "\n",
    "# Export config\n",
    "with open(config_path, 'w') as outfile:\n",
    "    json.dump(config, outfile, sort_keys=True)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627dea9-3cd6-421d-a84b-040494db39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch parallel computing (opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1521ed-e66a-4fe6-b959-6ccca5e06982",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222925f-2833-4cc0-9050-04f595a539a1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8e35e-f37a-4899-899a-51d23f19d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_FC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.GRU = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.FC = nn.Linear(hidden_size, output_size)\n",
    "        self.GRU.weight_ih_l0.data.fill_(0)\n",
    "        self.GRU.weight_hh_l0.data.fill_(0)\n",
    "        self.FC.weight.data.fill_(0)\n",
    "        self.input_length = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_size\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn) = self.GRU(x, (h0.detach()))\n",
    "        out = self.FC(out[:, -1, :])\n",
    "        out = torch.reshape(out, (out.size()[0], 1, out.size()[-1]))\n",
    "        return out\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = torch.ones(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        #hidden = weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79d625-d9f2-47d1-81ce-28f3e1987dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44f379-9e5d-4994-a9e2-d3ea7a7fa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulate to Dataloader\n",
    "os.chdir(config[\"Path_IVT_calculation\"])\n",
    "isDrop = True\n",
    "train_loader = DataLoader(torch.load(config[\"ML_train_set_name\"]), \n",
    "                          batch_size = config[\"ML_batch_size\"],\n",
    "                          drop_last = isDrop,\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "valid_loader = DataLoader(torch.load(config[\"ML_valid_set_name\"]), \n",
    "                          batch_size = config[\"ML_batch_size\"], \n",
    "                          drop_last = isDrop,\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "test_loader = DataLoader(torch.load(config[\"ML_test_set_name\"]), \n",
    "                         batch_size = config[\"ML_batch_size\"], \n",
    "                         drop_last = isDrop,\n",
    "                         shuffle = False,\n",
    "                         pin_memory = True)\n",
    "with np.load(config[\"IVT_SVD_fname\"]) as dataset:\n",
    "    feature_num = int(dataset['feature_threshold'][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5facef-56f3-40c2-b872-0c81bc617dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    \n",
    "    # Pre train stage\n",
    "        # model_dict\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "        # train parameter\n",
    "    n_epochs, best_loss, step, early_stop_count = config['ML_n_epochs'], math.inf, 0, 0\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "    # Optimizer\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr = config['ML_learning_rate'], \n",
    "                                 weight_decay = config['ML_weight_decay'])\n",
    "    \n",
    "    scheduler_Cycle = CosineAnnealingWarmRestarts(optimizer, T_0 = 50, T_mult = 5, eta_min = config['ML_weight_decay']/1e4)\n",
    "    scheduler_Decay = StepLR(optimizer, step_size = 50, gamma = 0.3)\n",
    "        # Training & Validating\n",
    "    mean_train_loss_record = []\n",
    "    mean_valid_loss_record = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training stage\n",
    "        # Init\n",
    "        model.train()\n",
    "        loss_record = []\n",
    "        #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "        for batch, (x, y, t) in enumerate(train_loader):\n",
    "            # Reset gradient\n",
    "            optimizer.zero_grad()\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            # cuda if possible\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Modify batch size in hidden state\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            pred = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(pred[:,-1,:], y[:,-1,:])\n",
    "            # Backward propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            # Update model parameter\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            step += 1\n",
    "            # Detach unused graph\n",
    "            #hidden.detach_()\n",
    "            loss_record.append(loss.detach().item())\n",
    "        scheduler_Cycle.step()\n",
    "        #scheduler_Decay.step()\n",
    "        # Train loss\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        mean_train_loss_record.append(mean_train_loss)\n",
    "        \n",
    "        # Validating stage\n",
    "        # Init\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y, t in valid_loader:\n",
    "            # cuda if possible\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Modify batch size in hidden state\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            # Skip gradient update and backward propagation\n",
    "            with torch.no_grad():\n",
    "                # Forward propagation\n",
    "                pred = model(x)\n",
    "                # Calculate loss\n",
    "                loss = criterion(pred[:,-1,:], y[:,-1,:])\n",
    "            \n",
    "            # Detach loss\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        # Valid loss\n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        mean_valid_loss_record.append(mean_valid_loss)\n",
    "        \n",
    "        # Show progress\n",
    "        if (epoch%10==0):\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.7f}, Valid loss: {mean_valid_loss:.7f}')\n",
    "        \n",
    "        # Save model parameter\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            os.chdir(config['ML_model_path'])\n",
    "            torch.save(model, config['ML_model_name']) # Save your best model\n",
    "            # print('Saving model with loss {:.5f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "            \n",
    "        # Early stop\n",
    "        if early_stop_count >= config['ML_early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return hidden, mean_train_loss_record, mean_valid_loss_record\n",
    "    return hidden, mean_train_loss_record, mean_valid_loss_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbe4c1-9568-4308-9884-f3702d113a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(config[\"Path_root\"])\n",
    "model = GRU_FC(input_size = feature_num,\n",
    "                 hidden_size = 76,\n",
    "                 output_size = feature_num,\n",
    "                 num_layers = 1).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "hidden, train_loss, valid_loss = trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ddb38-990d-4072-b191-dc3dd2dc562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47d5b2-74a7-4ed0-81a5-197160974a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval() # Set your model to evaluation mode.\n",
    "preds = []\n",
    "targets = []\n",
    "times = []\n",
    "hidden = model.init_hidden(config['ML_batch_size'])\n",
    "for i, (x,y,t) in enumerate(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    t = t.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred, hidden = model(x, hidden)\n",
    "        preds.append(pred.detach().cpu()[:,-1,:])\n",
    "        targets.append(y.detach().cpu()[:,-1,:])\n",
    "        times.append(t.detach().cpu()[:,-1,:])\n",
    "preds = torch.cat(preds, dim=0).numpy()\n",
    "targets = torch.cat(targets, dim=0).numpy()\n",
    "times = torch.cat(times, dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e600f6c-9ddf-48cf-aa3e-cd81d1707408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "os.chdir(config[\"ImgPath\"])\n",
    "t_interval = times[:,-1] - times[0,-1]\n",
    "for idx in range(feature_num):\n",
    "    plt.figure(figsize=(12,8), dpi = 200)\n",
    "    plt.plot(t_interval,preds[:,idx], label = \"predict\", zorder = 3)\n",
    "    plt.plot(t_interval,targets[:,idx], label = \"target\", zorder = 2)\n",
    "    plt.legend(loc = 1, prop={'size': 20})\n",
    "    plt.title(f\"Time structure of filtered SVD Spatial mode:{idx}\")\n",
    "    plt.savefig(f\"Time series, mode:{idx}\")\n",
    "    plt.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fdd01-3f0e-41d5-9d31-b71a3ed4f008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unused blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
