{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322072e3-6e26-410c-adfc-bca09189e6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f678f266-2ddd-48a4-9a1a-4b044eba2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7892ebe-ef6f-4cc0-b752-07c9d27e87f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cae166a-9711-4fe1-9c81-506a49e3290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config path\n",
    "root = '/Volumes/Expansion/User_Backup/b08209033/111-2_IVT_analysis/'\n",
    "folder = '2023_0321'\n",
    "file = 'src/config.json'\n",
    "config_path = os.path.join(os.path.join(root, folder), file)\n",
    "\n",
    "# Import config\n",
    "with open(config_path) as infile:\n",
    "    config = json.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "# Update config\n",
    "config.update({\"ML_batch_size\": 8})\n",
    "config.update({\"ML_n_epochs\": 10000})\n",
    "config.update({\"ML_learning_rate\": 5e-4})\n",
    "config.update({\"ML_weight_decay\": 0})\n",
    "config.update({\"ML_early_stop\": 1000})\n",
    "config.update({\"ML_model_path\": os.path.join(config[\"SubFolderPath\"], \"models\")})\n",
    "config.update({\"ML_model_name\": \"model.pt\"})\n",
    "\n",
    "# Export config\n",
    "with open(config_path, 'w') as outfile:\n",
    "    json.dump(config, outfile, sort_keys=True)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c343c60-f920-42c6-8f32-2ed87b82e577",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config (ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1521ed-e66a-4fe6-b959-6ccca5e06982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222925f-2833-4cc0-9050-04f595a539a1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e8e35e-f37a-4899-899a-51d23f19d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.GRU = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.GRU.weight_ih_l0.data.fill_(0)\n",
    "        self.GRU.weight_hh_l0.data.fill_(0)\n",
    "        self.input_length = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_size\n",
    "        \n",
    "    def forward(self, x, hidden_state):\n",
    "        hidden_state[-1] = 0\n",
    "        output, hidden_state = self.GRU(x, hidden_state)\n",
    "        return output, hidden_state\n",
    "        #return output, x[:,0,:].reshape(1,-1,self.hidden_dim)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = torch.ones(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        #hidden = weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79d625-d9f2-47d1-81ce-28f3e1987dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Undetermined blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c44f379-9e5d-4994-a9e2-d3ea7a7fa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulate to Dataloader\n",
    "os.chdir(config[\"IVTPath\"])\n",
    "isDrop = True\n",
    "train_loader = DataLoader(torch.load(config[\"ML_train_set_name\"]), \n",
    "                          batch_size = config[\"ML_batch_size\"],\n",
    "                          drop_last = isDrop,\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "valid_loader = DataLoader(torch.load(config[\"ML_valid_set_name\"]), \n",
    "                          batch_size = config[\"ML_batch_size\"], \n",
    "                          drop_last = isDrop,\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "test_loader = DataLoader(torch.load(config[\"ML_test_set_name\"]), \n",
    "                         batch_size = config[\"ML_batch_size\"], \n",
    "                         drop_last = isDrop,\n",
    "                         shuffle = False,\n",
    "                         pin_memory = True)\n",
    "with np.load(config[\"IVT_SVD_fname\"]) as dataset:\n",
    "    feature_num = int(dataset['feature_threshold'][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5facef-56f3-40c2-b872-0c81bc617dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    \n",
    "    # Pre train stage\n",
    "        # model_dict\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "        # train parameter\n",
    "    n_epochs, best_loss, step, early_stop_count = config['ML_n_epochs'], math.inf, 0, 0\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "    # Optimizer\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr = config['ML_learning_rate'], \n",
    "                                 weight_decay = config['ML_weight_decay'])\n",
    "    \n",
    "    scheduler_Cycle = CosineAnnealingWarmRestarts(optimizer, T_0 = 50, T_mult = 5, eta_min = config['ML_weight_decay']/1e4)\n",
    "    scheduler_Decay = StepLR(optimizer, step_size = 50, gamma = 0.3)\n",
    "        # Training & Validating\n",
    "    mean_train_loss_record = []\n",
    "    mean_valid_loss_record = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training stage\n",
    "        # Init\n",
    "        model.train()\n",
    "        loss_record = []\n",
    "        hidden = model.init_hidden(config['ML_batch_size'])\n",
    "        for batch, (x, y, t) in enumerate(train_loader):\n",
    "            # Reset gradient\n",
    "            optimizer.zero_grad()\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            # cuda if possible\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Modify batch size in hidden state\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            pred, hidden = model(x, hidden)\n",
    "            # Calculate loss\n",
    "            loss = criterion(pred[:,-1,:], y[:,-1,:])\n",
    "            # Backward propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            # Update model parameter\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            step += 1\n",
    "            # Detach unused graph\n",
    "            hidden.detach_()\n",
    "            loss_record.append(loss.detach().item())\n",
    "        #scheduler_Cycle.step()\n",
    "        scheduler_Decay.step()\n",
    "        # Train loss\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        mean_train_loss_record.append(mean_train_loss)\n",
    "        \n",
    "        # Validating stage\n",
    "        # Init\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y, t in valid_loader:\n",
    "            # cuda if possible\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Modify batch size in hidden state\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            # Skip gradient update and backward propagation\n",
    "            with torch.no_grad():\n",
    "                # Forward propagation\n",
    "                pred, hidden = model(x, hidden)\n",
    "                # Calculate loss\n",
    "                loss = criterion(pred[:,-1,:], y[:,-1,:])\n",
    "            \n",
    "            # Detach loss\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        # Valid loss\n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        mean_valid_loss_record.append(mean_valid_loss)\n",
    "        \n",
    "        # Show progress\n",
    "        if (epoch%10==0):\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.7f}, Valid loss: {mean_valid_loss:.7f}')\n",
    "        \n",
    "        # Save model parameter\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            os.chdir(config['ML_model_path'])\n",
    "            torch.save(model, config['ML_model_name']) # Save your best model\n",
    "            # print('Saving model with loss {:.5f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "            \n",
    "        # Early stop\n",
    "        if early_stop_count >= config['ML_early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return hidden, mean_train_loss_record, mean_valid_loss_record\n",
    "    return hidden, mean_train_loss_record, mean_valid_loss_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2abbe4c1-9568-4308-9884-f3702d113a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000]: Train loss: 0.1226401, Valid loss: 0.1080412\n",
      "Epoch [11/10000]: Train loss: 0.0785357, Valid loss: 0.0840111\n",
      "Epoch [21/10000]: Train loss: 0.0777352, Valid loss: 0.0836152\n",
      "Epoch [31/10000]: Train loss: 0.0774326, Valid loss: 0.0836049\n",
      "Epoch [41/10000]: Train loss: 0.0772116, Valid loss: 0.0836159\n",
      "Epoch [51/10000]: Train loss: 0.0766482, Valid loss: 0.0834582\n",
      "Epoch [61/10000]: Train loss: 0.0764804, Valid loss: 0.0834265\n",
      "Epoch [71/10000]: Train loss: 0.0764338, Valid loss: 0.0834400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFolderPath\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m My_Model(input_size \u001b[38;5;241m=\u001b[39m feature_num,\n\u001b[1;32m      3\u001b[0m                  hidden_size \u001b[38;5;241m=\u001b[39m feature_num,\n\u001b[1;32m      4\u001b[0m                  num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# put your model and data on the same computation device.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m hidden, train_loss, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [6], line 37\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Modify batch size in hidden state\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#hidden = model.init_hidden(config['ML_batch_size'])\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m pred, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:], y[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:])\n",
      "File \u001b[0;32m/Users/Shared/miniconda3/envs/default_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [4], line 13\u001b[0m, in \u001b[0;36mMy_Model.forward\u001b[0;34m(self, x, hidden_state)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden_state):\n\u001b[1;32m     12\u001b[0m     hidden_state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     output, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden_state\n",
      "File \u001b[0;32m/Users/Shared/miniconda3/envs/default_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Users/Shared/miniconda3/envs/default_env/lib/python3.9/site-packages/torch/nn/modules/rnn.py:950\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 950\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    954\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(config[\"FolderPath\"])\n",
    "model = My_Model(input_size = feature_num,\n",
    "                 hidden_size = feature_num,\n",
    "                 num_layers = 1).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "hidden, train_loss, valid_loss = trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ddb38-990d-4072-b191-dc3dd2dc562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47d5b2-74a7-4ed0-81a5-197160974a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval() # Set your model to evaluation mode.\n",
    "preds = []\n",
    "targets = []\n",
    "times = []\n",
    "hidden = model.init_hidden(config['ML_batch_size'])\n",
    "for i, (x,y,t) in enumerate(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    t = t.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred, hidden = model(x, hidden)\n",
    "        preds.append(pred.detach().cpu()[:,-1,:])\n",
    "        targets.append(y.detach().cpu()[:,-1,:])\n",
    "        times.append(t.detach().cpu()[:,-1,:])\n",
    "preds = torch.cat(preds, dim=0).numpy()\n",
    "targets = torch.cat(targets, dim=0).numpy()\n",
    "times = torch.cat(times, dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e600f6c-9ddf-48cf-aa3e-cd81d1707408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "os.chdir(config[\"ImgPath\"])\n",
    "t_interval = times[:,-1] - times[0,-1]\n",
    "for idx in range(feature_num):\n",
    "    plt.figure(figsize=(12,8), dpi = 200)\n",
    "    plt.plot(t_interval,preds[:,idx], label = \"predict\", zorder = 3)\n",
    "    plt.plot(t_interval,targets[:,idx], label = \"target\", zorder = 2)\n",
    "    plt.legend(loc = 1, prop={'size': 20})\n",
    "    plt.title(f\"Time structure of filtered SVD Spatial mode:{idx}\")\n",
    "    plt.savefig(f\"Time series, mode:{idx}\")\n",
    "    plt.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fdd01-3f0e-41d5-9d31-b71a3ed4f008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unused blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:default_env] *",
   "language": "python",
   "name": "conda-env-default_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
