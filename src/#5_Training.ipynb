{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322072e3-6e26-410c-adfc-bca09189e6a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f678f266-2ddd-48a4-9a1a-4b044eba2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7892ebe-ef6f-4cc0-b752-07c9d27e87f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cae166a-9711-4fe1-9c81-506a49e3290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config path\n",
    "root = '/Volumes/Expansion/User_Backup/b08209033/111-2_IVT_analysis/'\n",
    "folder = '2023_0330'\n",
    "file = 'src/config.json'\n",
    "config_path = os.path.join(os.path.join(root, folder), file)\n",
    "\n",
    "# Import config\n",
    "with open(config_path) as infile:\n",
    "    config = json.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "# Update config\n",
    "config.update({\"ML_batch_size\": 32})\n",
    "config.update({\"ML_n_epochs\": 10000})\n",
    "config.update({\"ML_learning_rate\": 1e-4})\n",
    "config.update({\"ML_weight_decay\": 0})\n",
    "config.update({\"ML_early_stop\": 1000})\n",
    "config.update({\"ML_model_path\": os.path.join(config[\"SubFolderPath\"], \"models\")})\n",
    "config.update({\"ML_model_name\": \"model.pt\"})\n",
    "\n",
    "# Export config\n",
    "with open(config_path, 'w') as outfile:\n",
    "    json.dump(config, outfile, sort_keys=True)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c343c60-f920-42c6-8f32-2ed87b82e577",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config (ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1521ed-e66a-4fe6-b959-6ccca5e06982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222925f-2833-4cc0-9050-04f595a539a1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e8e35e-f37a-4899-899a-51d23f19d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.GRU = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.FC = nn.Linear(hidden_size, output_size)\n",
    "        self.GRU.weight_ih_l0.data.fill_(0)\n",
    "        self.GRU.weight_hh_l0.data.fill_(0)\n",
    "        self.FC.weight.data.fill_(0)\n",
    "        self.input_length = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn) = self.GRU(x, (h0.detach()))\n",
    "        out = self.FC(out[:, -1, :])\n",
    "        out = torch.reshape(out, (out.size()[0], 1, out.size()[-1]))\n",
    "        return out\n",
    "        \"\"\"\n",
    "        hidden_state[-1] = 0\n",
    "        output, hidden_state = self.GRU(x, hidden_state)\n",
    "        return output, hidden_state\n",
    "        #return output, x[:,0,:].reshape(1,-1,self.hidden_dim)\n",
    "        \"\"\"\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = torch.ones(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        #hidden = weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79d625-d9f2-47d1-81ce-28f3e1987dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Undetermined blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c44f379-9e5d-4994-a9e2-d3ea7a7fa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulate to Dataloader\n",
    "os.chdir(config[\"IVTPath\"])\n",
    "isDrop = True\n",
    "train_loader = DataLoader(torch.load(config[\"ML_train_set_name\"]), \n",
    "                          batch_size = config[\"ML_batch_size\"],\n",
    "                          drop_last = isDrop,\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "valid_loader = DataLoader(torch.load(config[\"ML_valid_set_name\"]), \n",
    "                          batch_size = config[\"ML_batch_size\"], \n",
    "                          drop_last = isDrop,\n",
    "                          shuffle = False,\n",
    "                          pin_memory = True)\n",
    "test_loader = DataLoader(torch.load(config[\"ML_test_set_name\"]), \n",
    "                         batch_size = config[\"ML_batch_size\"], \n",
    "                         drop_last = isDrop,\n",
    "                         shuffle = False,\n",
    "                         pin_memory = True)\n",
    "with np.load(config[\"IVT_SVD_fname\"]) as dataset:\n",
    "    feature_num = int(dataset['feature_threshold'][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5facef-56f3-40c2-b872-0c81bc617dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    \n",
    "    # Pre train stage\n",
    "        # model_dict\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "        # train parameter\n",
    "    n_epochs, best_loss, step, early_stop_count = config['ML_n_epochs'], math.inf, 0, 0\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.L1Loss(reduction='mean').to(device)\n",
    "    # Optimizer\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr = config['ML_learning_rate'], \n",
    "                                 weight_decay = config['ML_weight_decay'])\n",
    "    \n",
    "    scheduler_Cycle = CosineAnnealingWarmRestarts(optimizer, T_0 = 50, T_mult = 5, eta_min = config['ML_weight_decay']/1e4)\n",
    "    scheduler_Decay = StepLR(optimizer, step_size = 50, gamma = 0.3)\n",
    "        # Training & Validating\n",
    "    mean_train_loss_record = []\n",
    "    mean_valid_loss_record = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training stage\n",
    "        # Init\n",
    "        model.train()\n",
    "        loss_record = []\n",
    "        #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "        for batch, (x, y, t) in enumerate(train_loader):\n",
    "            # Reset gradient\n",
    "            optimizer.zero_grad()\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            # cuda if possible\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Modify batch size in hidden state\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            pred = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(pred[:,-1,:], y[:,-1,:])\n",
    "            # Backward propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            # Update model parameter\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            step += 1\n",
    "            # Detach unused graph\n",
    "            #hidden.detach_()\n",
    "            loss_record.append(loss.detach().item())\n",
    "        scheduler_Cycle.step()\n",
    "        #scheduler_Decay.step()\n",
    "        # Train loss\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        mean_train_loss_record.append(mean_train_loss)\n",
    "        \n",
    "        # Validating stage\n",
    "        # Init\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y, t in valid_loader:\n",
    "            # cuda if possible\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Modify batch size in hidden state\n",
    "            #hidden = model.init_hidden(config['ML_batch_size'])\n",
    "            # Skip gradient update and backward propagation\n",
    "            with torch.no_grad():\n",
    "                # Forward propagation\n",
    "                pred = model(x)\n",
    "                # Calculate loss\n",
    "                loss = criterion(pred[:,-1,:], y[:,-1,:])\n",
    "            \n",
    "            # Detach loss\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        # Valid loss\n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        mean_valid_loss_record.append(mean_valid_loss)\n",
    "        \n",
    "        # Show progress\n",
    "        if (epoch%10==0):\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.7f}, Valid loss: {mean_valid_loss:.7f}')\n",
    "        \n",
    "        # Save model parameter\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            os.chdir(config['ML_model_path'])\n",
    "            torch.save(model, config['ML_model_name']) # Save your best model\n",
    "            # print('Saving model with loss {:.5f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "            \n",
    "        # Early stop\n",
    "        if early_stop_count >= config['ML_early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return hidden, mean_train_loss_record, mean_valid_loss_record\n",
    "    return hidden, mean_train_loss_record, mean_valid_loss_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbe4c1-9568-4308-9884-f3702d113a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000]: Train loss: 0.1466994, Valid loss: 0.1504419\n",
      "Epoch [11/10000]: Train loss: 0.1401648, Valid loss: 0.1479433\n",
      "Epoch [21/10000]: Train loss: 0.1313662, Valid loss: 0.1402158\n",
      "Epoch [31/10000]: Train loss: 0.1242571, Valid loss: 0.1334321\n",
      "Epoch [41/10000]: Train loss: 0.1211557, Valid loss: 0.1306247\n",
      "Epoch [51/10000]: Train loss: 0.1202025, Valid loss: 0.1288615\n",
      "Epoch [61/10000]: Train loss: 0.1047248, Valid loss: 0.1125815\n",
      "Epoch [71/10000]: Train loss: 0.0904057, Valid loss: 0.0973878\n",
      "Epoch [81/10000]: Train loss: 0.0824299, Valid loss: 0.0887180\n",
      "Epoch [91/10000]: Train loss: 0.0785622, Valid loss: 0.0843073\n",
      "Epoch [101/10000]: Train loss: 0.0770520, Valid loss: 0.0827319\n",
      "Epoch [111/10000]: Train loss: 0.0762957, Valid loss: 0.0820512\n",
      "Epoch [121/10000]: Train loss: 0.0758429, Valid loss: 0.0816938\n",
      "Epoch [131/10000]: Train loss: 0.0755382, Valid loss: 0.0814965\n",
      "Epoch [141/10000]: Train loss: 0.0753053, Valid loss: 0.0813858\n",
      "Epoch [151/10000]: Train loss: 0.0751175, Valid loss: 0.0813062\n",
      "Epoch [161/10000]: Train loss: 0.0749595, Valid loss: 0.0812456\n",
      "Epoch [171/10000]: Train loss: 0.0748241, Valid loss: 0.0812066\n",
      "Epoch [181/10000]: Train loss: 0.0747050, Valid loss: 0.0811692\n",
      "Epoch [191/10000]: Train loss: 0.0746043, Valid loss: 0.0811487\n",
      "Epoch [201/10000]: Train loss: 0.0745174, Valid loss: 0.0811312\n",
      "Epoch [211/10000]: Train loss: 0.0744440, Valid loss: 0.0811151\n",
      "Epoch [221/10000]: Train loss: 0.0743830, Valid loss: 0.0811063\n",
      "Epoch [231/10000]: Train loss: 0.0743326, Valid loss: 0.0810997\n",
      "Epoch [241/10000]: Train loss: 0.0742925, Valid loss: 0.0810924\n",
      "Epoch [251/10000]: Train loss: 0.0742612, Valid loss: 0.0810864\n",
      "Epoch [261/10000]: Train loss: 0.0742374, Valid loss: 0.0810833\n",
      "Epoch [271/10000]: Train loss: 0.0742209, Valid loss: 0.0810811\n",
      "Epoch [281/10000]: Train loss: 0.0742102, Valid loss: 0.0810803\n",
      "Epoch [291/10000]: Train loss: 0.0742048, Valid loss: 0.0810803\n",
      "Epoch [301/10000]: Train loss: 0.0744194, Valid loss: 0.0810774\n",
      "Epoch [311/10000]: Train loss: 0.0742524, Valid loss: 0.0810611\n",
      "Epoch [321/10000]: Train loss: 0.0740834, Valid loss: 0.0810325\n",
      "Epoch [331/10000]: Train loss: 0.0739194, Valid loss: 0.0810085\n",
      "Epoch [341/10000]: Train loss: 0.0737581, Valid loss: 0.0809888\n",
      "Epoch [351/10000]: Train loss: 0.0736000, Valid loss: 0.0809560\n",
      "Epoch [361/10000]: Train loss: 0.0734434, Valid loss: 0.0809322\n",
      "Epoch [371/10000]: Train loss: 0.0732917, Valid loss: 0.0809174\n",
      "Epoch [381/10000]: Train loss: 0.0731441, Valid loss: 0.0809207\n",
      "Epoch [391/10000]: Train loss: 0.0729985, Valid loss: 0.0809083\n",
      "Epoch [401/10000]: Train loss: 0.0728568, Valid loss: 0.0809010\n",
      "Epoch [411/10000]: Train loss: 0.0727188, Valid loss: 0.0808900\n",
      "Epoch [421/10000]: Train loss: 0.0725837, Valid loss: 0.0808917\n",
      "Epoch [431/10000]: Train loss: 0.0724513, Valid loss: 0.0808906\n",
      "Epoch [441/10000]: Train loss: 0.0723249, Valid loss: 0.0808885\n",
      "Epoch [451/10000]: Train loss: 0.0721989, Valid loss: 0.0808935\n",
      "Epoch [461/10000]: Train loss: 0.0720790, Valid loss: 0.0808857\n",
      "Epoch [471/10000]: Train loss: 0.0719632, Valid loss: 0.0808936\n",
      "Epoch [481/10000]: Train loss: 0.0718515, Valid loss: 0.0808932\n",
      "Epoch [491/10000]: Train loss: 0.0717442, Valid loss: 0.0808982\n",
      "Epoch [501/10000]: Train loss: 0.0716378, Valid loss: 0.0809097\n",
      "Epoch [511/10000]: Train loss: 0.0715358, Valid loss: 0.0809215\n",
      "Epoch [521/10000]: Train loss: 0.0714354, Valid loss: 0.0809410\n",
      "Epoch [531/10000]: Train loss: 0.0713381, Valid loss: 0.0809453\n",
      "Epoch [541/10000]: Train loss: 0.0712418, Valid loss: 0.0809675\n",
      "Epoch [551/10000]: Train loss: 0.0711466, Valid loss: 0.0809684\n",
      "Epoch [561/10000]: Train loss: 0.0710563, Valid loss: 0.0809840\n",
      "Epoch [571/10000]: Train loss: 0.0709676, Valid loss: 0.0809965\n",
      "Epoch [581/10000]: Train loss: 0.0708828, Valid loss: 0.0810065\n",
      "Epoch [591/10000]: Train loss: 0.0707988, Valid loss: 0.0810286\n",
      "Epoch [601/10000]: Train loss: 0.0707172, Valid loss: 0.0810493\n",
      "Epoch [611/10000]: Train loss: 0.0706363, Valid loss: 0.0810676\n",
      "Epoch [621/10000]: Train loss: 0.0705582, Valid loss: 0.0810818\n",
      "Epoch [631/10000]: Train loss: 0.0704814, Valid loss: 0.0811076\n",
      "Epoch [641/10000]: Train loss: 0.0704066, Valid loss: 0.0811174\n",
      "Epoch [651/10000]: Train loss: 0.0703348, Valid loss: 0.0811363\n",
      "Epoch [661/10000]: Train loss: 0.0702657, Valid loss: 0.0811497\n",
      "Epoch [671/10000]: Train loss: 0.0701982, Valid loss: 0.0811623\n",
      "Epoch [681/10000]: Train loss: 0.0701311, Valid loss: 0.0811797\n",
      "Epoch [691/10000]: Train loss: 0.0700675, Valid loss: 0.0811879\n",
      "Epoch [701/10000]: Train loss: 0.0700052, Valid loss: 0.0812095\n",
      "Epoch [711/10000]: Train loss: 0.0699439, Valid loss: 0.0812245\n",
      "Epoch [721/10000]: Train loss: 0.0698856, Valid loss: 0.0812437\n",
      "Epoch [731/10000]: Train loss: 0.0698277, Valid loss: 0.0812663\n",
      "Epoch [741/10000]: Train loss: 0.0697726, Valid loss: 0.0812856\n",
      "Epoch [751/10000]: Train loss: 0.0697197, Valid loss: 0.0813048\n",
      "Epoch [761/10000]: Train loss: 0.0696661, Valid loss: 0.0813197\n",
      "Epoch [771/10000]: Train loss: 0.0696155, Valid loss: 0.0813357\n",
      "Epoch [781/10000]: Train loss: 0.0695665, Valid loss: 0.0813604\n",
      "Epoch [791/10000]: Train loss: 0.0695195, Valid loss: 0.0813763\n",
      "Epoch [801/10000]: Train loss: 0.0694705, Valid loss: 0.0814002\n",
      "Epoch [811/10000]: Train loss: 0.0694264, Valid loss: 0.0814209\n",
      "Epoch [821/10000]: Train loss: 0.0693824, Valid loss: 0.0814381\n",
      "Epoch [831/10000]: Train loss: 0.0693390, Valid loss: 0.0814592\n",
      "Epoch [841/10000]: Train loss: 0.0692979, Valid loss: 0.0814752\n",
      "Epoch [851/10000]: Train loss: 0.0692585, Valid loss: 0.0814935\n",
      "Epoch [861/10000]: Train loss: 0.0692201, Valid loss: 0.0815131\n",
      "Epoch [871/10000]: Train loss: 0.0691816, Valid loss: 0.0815333\n",
      "Epoch [881/10000]: Train loss: 0.0691452, Valid loss: 0.0815474\n",
      "Epoch [891/10000]: Train loss: 0.0691086, Valid loss: 0.0815623\n",
      "Epoch [901/10000]: Train loss: 0.0690728, Valid loss: 0.0815781\n",
      "Epoch [911/10000]: Train loss: 0.0690391, Valid loss: 0.0815937\n",
      "Epoch [921/10000]: Train loss: 0.0690064, Valid loss: 0.0816023\n",
      "Epoch [931/10000]: Train loss: 0.0689742, Valid loss: 0.0816184\n",
      "Epoch [941/10000]: Train loss: 0.0689431, Valid loss: 0.0816337\n",
      "Epoch [951/10000]: Train loss: 0.0689122, Valid loss: 0.0816457\n",
      "Epoch [961/10000]: Train loss: 0.0688826, Valid loss: 0.0816600\n",
      "Epoch [971/10000]: Train loss: 0.0688534, Valid loss: 0.0816757\n",
      "Epoch [981/10000]: Train loss: 0.0688268, Valid loss: 0.0816879\n",
      "Epoch [991/10000]: Train loss: 0.0687999, Valid loss: 0.0816983\n",
      "Epoch [1001/10000]: Train loss: 0.0687742, Valid loss: 0.0817102\n",
      "Epoch [1011/10000]: Train loss: 0.0687483, Valid loss: 0.0817210\n",
      "Epoch [1021/10000]: Train loss: 0.0687240, Valid loss: 0.0817294\n",
      "Epoch [1031/10000]: Train loss: 0.0687004, Valid loss: 0.0817363\n",
      "Epoch [1041/10000]: Train loss: 0.0686766, Valid loss: 0.0817463\n",
      "Epoch [1051/10000]: Train loss: 0.0686548, Valid loss: 0.0817559\n",
      "Epoch [1061/10000]: Train loss: 0.0686334, Valid loss: 0.0817633\n",
      "Epoch [1071/10000]: Train loss: 0.0686128, Valid loss: 0.0817738\n",
      "Epoch [1081/10000]: Train loss: 0.0685929, Valid loss: 0.0817801\n",
      "Epoch [1091/10000]: Train loss: 0.0685733, Valid loss: 0.0817873\n",
      "Epoch [1101/10000]: Train loss: 0.0685550, Valid loss: 0.0817959\n",
      "Epoch [1111/10000]: Train loss: 0.0685373, Valid loss: 0.0818021\n",
      "Epoch [1121/10000]: Train loss: 0.0685195, Valid loss: 0.0818062\n",
      "Epoch [1131/10000]: Train loss: 0.0685036, Valid loss: 0.0818131\n"
     ]
    }
   ],
   "source": [
    "os.chdir(config[\"FolderPath\"])\n",
    "model = My_Model(input_size = feature_num,\n",
    "                 hidden_size = 76,\n",
    "                 output_size = feature_num,\n",
    "                 num_layers = 1).to(device) # put your model and data on the same computation device.\n",
    "\n",
    "hidden, train_loss, valid_loss = trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ddb38-990d-4072-b191-dc3dd2dc562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47d5b2-74a7-4ed0-81a5-197160974a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval() # Set your model to evaluation mode.\n",
    "preds = []\n",
    "targets = []\n",
    "times = []\n",
    "hidden = model.init_hidden(config['ML_batch_size'])\n",
    "for i, (x,y,t) in enumerate(test_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    t = t.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred, hidden = model(x, hidden)\n",
    "        preds.append(pred.detach().cpu()[:,-1,:])\n",
    "        targets.append(y.detach().cpu()[:,-1,:])\n",
    "        times.append(t.detach().cpu()[:,-1,:])\n",
    "preds = torch.cat(preds, dim=0).numpy()\n",
    "targets = torch.cat(targets, dim=0).numpy()\n",
    "times = torch.cat(times, dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e600f6c-9ddf-48cf-aa3e-cd81d1707408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "os.chdir(config[\"ImgPath\"])\n",
    "t_interval = times[:,-1] - times[0,-1]\n",
    "for idx in range(feature_num):\n",
    "    plt.figure(figsize=(12,8), dpi = 200)\n",
    "    plt.plot(t_interval,preds[:,idx], label = \"predict\", zorder = 3)\n",
    "    plt.plot(t_interval,targets[:,idx], label = \"target\", zorder = 2)\n",
    "    plt.legend(loc = 1, prop={'size': 20})\n",
    "    plt.title(f\"Time structure of filtered SVD Spatial mode:{idx}\")\n",
    "    plt.savefig(f\"Time series, mode:{idx}\")\n",
    "    plt.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fdd01-3f0e-41d5-9d31-b71a3ed4f008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unused blocks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
